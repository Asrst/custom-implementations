{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "713093cf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-29T08:12:26.773654Z",
     "iopub.status.busy": "2021-08-29T08:12:26.772422Z",
     "iopub.status.idle": "2021-08-29T08:12:34.788466Z",
     "shell.execute_reply": "2021-08-29T08:12:34.789165Z",
     "shell.execute_reply.started": "2021-08-29T08:07:47.902938Z"
    },
    "papermill": {
     "duration": 8.040227,
     "end_time": "2021-08-29T08:12:34.789688",
     "exception": false,
     "start_time": "2021-08-29T08:12:26.749461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/predict-human-emotions-from-audio/dataset/sample_submission.csv\n",
      "/kaggle/input/predict-human-emotions-from-audio/dataset/train.csv\n",
      "/kaggle/input/predict-human-emotions-from-audio/dataset/TestAudioFiles/13738.mp3\n",
      "/kaggle/input/predict-human-emotions-from-audio/dataset/TestAudioFiles/28919.mp3\n",
      "/kaggle/input/predict-human-emotions-from-audio/dataset/TrainAudioFiles/23694.mp3\n",
      "/kaggle/input/predict-human-emotions-from-audio/dataset/TrainAudioFiles/11507.mp3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for i, filename in enumerate(filenames):\n",
    "        if i < 2:\n",
    "            print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83831695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T08:12:34.838254Z",
     "iopub.status.busy": "2021-08-29T08:12:34.837368Z",
     "iopub.status.idle": "2021-08-29T08:12:49.905171Z",
     "shell.execute_reply": "2021-08-29T08:12:49.904515Z",
     "shell.execute_reply.started": "2021-08-29T08:07:58.438629Z"
    },
    "papermill": {
     "duration": 15.093361,
     "end_time": "2021-08-29T08:12:49.905348",
     "exception": false,
     "start_time": "2021-08-29T08:12:34.811987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install tensorflow.io==0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9082c3db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T08:12:49.952636Z",
     "iopub.status.busy": "2021-08-29T08:12:49.951836Z",
     "iopub.status.idle": "2021-08-29T08:12:49.971715Z",
     "shell.execute_reply": "2021-08-29T08:12:49.971105Z",
     "shell.execute_reply.started": "2021-08-29T08:08:09.406168Z"
    },
    "papermill": {
     "duration": 0.046127,
     "end_time": "2021-08-29T08:12:49.971858",
     "exception": false,
     "start_time": "2021-08-29T08:12:49.925731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5816, 2492)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = \"/kaggle/input/predict-human-emotions-from-audio/dataset/train.csv\"\n",
    "test_csv = \"/kaggle/input/predict-human-emotions-from-audio/dataset/test.csv\"\n",
    "TRAIN_fp = \"/kaggle/input/predict-human-emotions-from-audio/dataset/TrainAudioFiles/\"\n",
    "TEST_fp = \"/kaggle/input/predict-human-emotions-from-audio/dataset/TestAudioFiles/\"\n",
    "\n",
    "train_files = [fn for fn in os.listdir(TRAIN_fp) if fn.split('.')[-1] in ['mp3', 'wav']]\n",
    "test_files = [fn for fn in os.listdir(TEST_fp) if fn.split('.')[-1] in ['mp3', 'wav']]\n",
    "len(train_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f1bae02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T08:12:50.016718Z",
     "iopub.status.busy": "2021-08-29T08:12:50.015962Z",
     "iopub.status.idle": "2021-08-29T08:12:50.208243Z",
     "shell.execute_reply": "2021-08-29T08:12:50.207541Z",
     "shell.execute_reply.started": "2021-08-29T08:08:09.427052Z"
    },
    "papermill": {
     "duration": 0.217426,
     "end_time": "2021-08-29T08:12:50.208387",
     "exception": false,
     "start_time": "2021-08-29T08:12:49.990961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5816, 2),\n",
       " Index(['filename', 'emotion'], dtype='object'),\n",
       " neutral     2630\n",
       " joy          967\n",
       " surprise     640\n",
       " anger        596\n",
       " sadness      344\n",
       " fear         328\n",
       " disgust      311\n",
       " Name: emotion, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_csv)\n",
    "train_df.shape, train_df.columns, train_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42404704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T08:12:50.252095Z",
     "iopub.status.busy": "2021-08-29T08:12:50.251146Z",
     "iopub.status.idle": "2021-08-29T08:12:50.267256Z",
     "shell.execute_reply": "2021-08-29T08:12:50.266546Z",
     "shell.execute_reply.started": "2021-08-29T08:08:09.604446Z"
    },
    "papermill": {
     "duration": 0.040228,
     "end_time": "2021-08-29T08:12:50.267426",
     "exception": false,
     "start_time": "2021-08-29T08:12:50.227198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2492, 1), Index(['filename'], dtype='object'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_csv)\n",
    "test_df.shape, test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea9eef34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T08:12:50.324332Z",
     "iopub.status.busy": "2021-08-29T08:12:50.323249Z",
     "iopub.status.idle": "2021-08-29T08:12:53.368124Z",
     "shell.execute_reply": "2021-08-29T08:12:53.368631Z",
     "shell.execute_reply.started": "2021-08-29T08:08:09.627100Z"
    },
    "papermill": {
     "duration": 3.080419,
     "end_time": "2021-08-29T08:12:53.368849",
     "exception": false,
     "start_time": "2021-08-29T08:12:50.288430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44982,), 44100, (44982,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa.util.utils as util\n",
    "import librosa\n",
    "import librosa.display\n",
    "import audioread\n",
    "\n",
    "def audioread_load(path, offset=0.0,\n",
    "                   duration=None, dtype=np.float32):\n",
    "    \n",
    "    \"\"\"\n",
    "    Load an audio buffer using audioread.\n",
    "    This loads one block at a time, and then concatenates the results.\n",
    "    \"\"\"\n",
    "    y = []\n",
    "    with audioread.audio_open(path) as input_file:\n",
    "        sr_native = input_file.samplerate\n",
    "        n_channels = input_file.channels\n",
    "\n",
    "        s_start = int(np.round(sr_native * offset)) * n_channels\n",
    "\n",
    "        if duration is None:\n",
    "            s_end = np.inf\n",
    "        else:\n",
    "            s_end = s_start + (int(np.round(sr_native * duration)) * n_channels)\n",
    "\n",
    "        n = 0\n",
    "        for frame in input_file:\n",
    "            frame = util.buf_to_float(frame, dtype=dtype)\n",
    "            n_prev = n\n",
    "            n = n + len(frame)\n",
    "\n",
    "            if n < s_start:\n",
    "                # offset is after the current frame\n",
    "                # keep reading\n",
    "                continue\n",
    "\n",
    "            if s_end < n_prev:\n",
    "                # we're off the end.  stop reading\n",
    "                break\n",
    "\n",
    "            if s_end < n:\n",
    "                # the end is in this frame.  crop.\n",
    "                frame = frame[: s_end - n_prev]\n",
    "\n",
    "            if n_prev <= s_start <= n:\n",
    "                # beginning is in this frame\n",
    "                frame = frame[(s_start - n_prev) :]\n",
    "                \n",
    "            # tack on the current frame\n",
    "            y.append(frame)\n",
    "    if y:\n",
    "        y = np.concatenate(y)\n",
    "        if n_channels > 1:\n",
    "            y = y.reshape((-1, n_channels)).T\n",
    "    else:\n",
    "        y = np.empty(0, dtype=dtype)\n",
    "        \n",
    "    if n_channels > 1:\n",
    "        y = librosa.to_mono(y)\n",
    "\n",
    "    return y, sr_native\n",
    "\n",
    "\n",
    "sample_fp = f\"{TRAIN_fp}/28967.mp3\"\n",
    "# y, sr = audioread_load(sample_fp, duration=5, sr=16000)\n",
    "y, sr = librosa.load(sample_fp, sr=None)\n",
    "yt,_ = librosa.effects.trim(y)\n",
    "y.shape, sr, yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e71d050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T08:12:53.425487Z",
     "iopub.status.busy": "2021-08-29T08:12:53.424477Z",
     "iopub.status.idle": "2021-08-29T08:12:53.429930Z",
     "shell.execute_reply": "2021-08-29T08:12:53.429252Z",
     "shell.execute_reply.started": "2021-08-29T08:08:12.263144Z"
    },
    "papermill": {
     "duration": 0.039888,
     "end_time": "2021-08-29T08:12:53.430107",
     "exception": false,
     "start_time": "2021-08-29T08:12:53.390219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'joy': 3,\n",
       " 'neutral': 4,\n",
       " 'sadness': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(train_df['emotion'].unique().tolist())\n",
    "map_class_to_id = dict(zip(classes, range(0, len(classes))))\n",
    "map_class_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f23f68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T08:12:53.501778Z",
     "iopub.status.busy": "2021-08-29T08:12:53.500733Z",
     "iopub.status.idle": "2021-08-29T08:12:53.505144Z",
     "shell.execute_reply": "2021-08-29T08:12:53.504449Z",
     "shell.execute_reply.started": "2021-08-29T08:08:12.276346Z"
    },
    "papermill": {
     "duration": 0.052845,
     "end_time": "2021-08-29T08:12:53.505301",
     "exception": false,
     "start_time": "2021-08-29T08:12:53.452456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    /kaggle/input/predict-human-emotions-from-audi...\n",
       " 1    /kaggle/input/predict-human-emotions-from-audi...\n",
       " Name: filename, dtype: object,\n",
       " 0    4\n",
       " 1    4\n",
       " Name: emotion, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths =  train_df['filename'].apply(lambda x:os.path.join(TRAIN_fp,x))\n",
    "class_ids = train_df['emotion'].apply(lambda n: map_class_to_id[n])\n",
    "filepaths.head(2), class_ids.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e92e6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T08:12:53.553522Z",
     "iopub.status.busy": "2021-08-29T08:12:53.552688Z",
     "iopub.status.idle": "2021-08-29T08:12:53.555875Z",
     "shell.execute_reply": "2021-08-29T08:12:53.555186Z",
     "shell.execute_reply.started": "2021-08-29T08:08:12.302647Z"
    },
    "papermill": {
     "duration": 0.029818,
     "end_time": "2021-08-29T08:12:53.556031",
     "exception": false,
     "start_time": "2021-08-29T08:12:53.526213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# main_ds = tf.data.Dataset.from_tensor_slices((filepaths, class_ids))\n",
    "# main_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e172d272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T08:12:53.610523Z",
     "iopub.status.busy": "2021-08-29T08:12:53.608363Z",
     "iopub.status.idle": "2021-08-29T08:12:59.930788Z",
     "shell.execute_reply": "2021-08-29T08:12:59.931413Z",
     "shell.execute_reply.started": "2021-08-29T08:08:12.314999Z"
    },
    "papermill": {
     "duration": 6.353148,
     "end_time": "2021-08-29T08:12:59.931664",
     "exception": false,
     "start_time": "2021-08-29T08:12:53.578516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow_io import experimental as tfio_exp\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_audio(fp):\n",
    "    y, sr = audioread_load(fp, duration=10)\n",
    "    if sr != 22050:\n",
    "        y = librosa.resample(y, sr, 22050)\n",
    "        sr = 22050\n",
    "    yt, _ = librosa.effects.trim(y)\n",
    "    return yt, sr\n",
    "\n",
    "#@tf.function\n",
    "def load_tf_audio(fp, target_sr = 22050):\n",
    "    ## tf audio-read\n",
    "    duration = 5\n",
    "    target_sr = 22050\n",
    "    audio = tfio.audio.AudioIOTensor(fp, dtype=tf.float32)\n",
    "    sr = tf.cast(audio.rate, dtype=tf.int64)\n",
    "    samples = tf.cast(duration * sr, dtype=tf.int32)\n",
    "    waveform = audio[:samples]\n",
    "    waveform = tfio.audio.resample(waveform, sr, target_sr)\n",
    "    waveform = tf.reduce_mean(waveform, axis=-1)\n",
    "    waveform = tf.cast(waveform, tf.float32)\n",
    "    \n",
    "    target_samples = tf.cast(duration*target_sr, dtype=tf.int32)\n",
    "    # pos = tfio_exp.audio.trim(waveform, axis=0, epsilon=0.1)\n",
    "    # waveform = waveform[pos[0]:pos[1]]\n",
    "    zeros = tf.math.maximum(samples - tf.shape(waveform)[0], 0)\n",
    "    paddings = [[zeros // 2, zeros // 2 + zeros % 2]]\n",
    "    # pad if audio is too short\n",
    "    pad_audio = tf.pad(waveform, paddings=paddings, mode='CONSTANT')\n",
    "    crop_audio = tf.image.random_crop(pad_audio, [samples])\n",
    "    \n",
    "    return crop_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a72c9040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T08:12:59.981665Z",
     "iopub.status.busy": "2021-08-29T08:12:59.980210Z",
     "iopub.status.idle": "2021-08-29T08:12:59.985682Z",
     "shell.execute_reply": "2021-08-29T08:12:59.986401Z",
     "shell.execute_reply.started": "2021-08-29T08:08:18.054243Z"
    },
    "papermill": {
     "duration": 0.032674,
     "end_time": "2021-08-29T08:12:59.986677",
     "exception": false,
     "start_time": "2021-08-29T08:12:59.954003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_waveform_and_label(fp, label):\n",
    "#     return load_tf_audio(fp), label\n",
    "\n",
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# waveform_ds = main_ds.map(get_waveform_and_label, num_parallel_calls=1)\n",
    "# waveform_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15179618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T08:13:00.049278Z",
     "iopub.status.busy": "2021-08-29T08:13:00.048541Z",
     "iopub.status.idle": "2021-08-29T08:13:00.051162Z",
     "shell.execute_reply": "2021-08-29T08:13:00.051768Z",
     "shell.execute_reply.started": "2021-08-29T08:08:18.060876Z"
    },
    "papermill": {
     "duration": 0.036697,
     "end_time": "2021-08-29T08:13:00.051970",
     "exception": false,
     "start_time": "2021-08-29T08:13:00.015273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mel_spectogram(audio, sr):\n",
    "    # tensor\n",
    "    waveform = tf.cast(audio, tf.float32)\n",
    "    # get spectrogram\n",
    "    spectrogram = tfio_exp.audio.spectrogram(\n",
    "        waveform, nfft=2048, window=512, stride=256)\n",
    "    # Convert to mel-spectrogram\n",
    "    mel_spectrogram = tfio_exp.audio.melscale(\n",
    "        spectrogram, rate=sr, mels=128, fmin=0, fmax=max(9000, sr/2))\n",
    "    db_mel_spect = tfio_exp.audio.dbscale(\n",
    "        mel_spectrogram, top_db=80)\n",
    "    # waveform.shape, processed.shape, mel_spectrogram.shape\n",
    "    # db_mel =  tf.expand_dims(db_mel_spect, axis=-1)\n",
    "    # resized = tf.image.resize(db_mel, [224, 224])\n",
    "    Xdb = db_mel_spect.numpy()\n",
    "    return Xdb\n",
    "\n",
    "def save_image(inp, path):\n",
    "    # print(path)\n",
    "    # figsize=(8,4)\n",
    "    f = plt.figure(frameon=False, facecolor=\"w\")\n",
    "    plt.imshow(inp, interpolation='nearest', aspect=\"auto\")\n",
    "    plt.axis('off')\n",
    "    # save the image\n",
    "    # plt.imsave(path, inp)\n",
    "    plt.savefig(path, bbox_inches='tight',\n",
    "                pad_inches=0)\n",
    "    plt.close(f)\n",
    "    return\n",
    "\n",
    "#     librosa.display.specshow(inp, y_axis='mel',\n",
    "#                              x_axis='time',\n",
    "#                              fmax=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a234296",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-08-29T08:13:00.102911Z",
     "iopub.status.busy": "2021-08-29T08:13:00.101675Z",
     "iopub.status.idle": "2021-08-29T09:24:44.822811Z",
     "shell.execute_reply": "2021-08-29T09:24:44.822128Z"
    },
    "papermill": {
     "duration": 4304.747218,
     "end_time": "2021-08-29T09:24:44.823021",
     "exception": false,
     "start_time": "2021-08-29T08:13:00.075803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aaf55c0a4ff40d5b5ba25c97222d877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5816 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Done...\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "save_path = \"/kaggle/working/TrainImages\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "    \n",
    "train_data = []\n",
    "for fn, label in tqdm(train_df.values[:]):\n",
    "    path_load = os.path.join(TRAIN_fp,fn)\n",
    "    waveform, sr = load_audio(path_load)\n",
    "    mel_spect = get_mel_spectogram(waveform, sr)\n",
    "    img_path = os.path.join(save_path, f\"{fn}.png\")\n",
    "    save_image(mel_spect, img_path)\n",
    "    train_data.append([f\"{fn}.png\", label]) \n",
    "    del waveform, mel_spect\n",
    "    gc.collect()\n",
    "\n",
    "train_data = pd.DataFrame(train_data, columns=['filename', 'emotion'])\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "print(\"Train Images Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cb370fd",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-08-29T09:24:44.905571Z",
     "iopub.status.busy": "2021-08-29T09:24:44.874327Z",
     "iopub.status.idle": "2021-08-29T09:55:15.718099Z",
     "shell.execute_reply": "2021-08-29T09:55:15.717399Z"
    },
    "papermill": {
     "duration": 1830.874052,
     "end_time": "2021-08-29T09:55:15.718250",
     "exception": false,
     "start_time": "2021-08-29T09:24:44.844198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76272f6e440457d9ea80176727d4654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images Done...\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "save_path = \"/kaggle/working/TestImages\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "    \n",
    "test_data = []\n",
    "for fn in tqdm(test_df['filename'].values[:]):\n",
    "    path_load = os.path.join(TEST_fp,fn)\n",
    "    waveform, sr = load_audio(path_load)\n",
    "    mel_spect = get_mel_spectogram(waveform, sr)\n",
    "    img_path = os.path.join(save_path, f\"{fn}.png\")\n",
    "    save_image(mel_spect, img_path)\n",
    "    test_data.append([f\"{fn}.png\", \"\"])\n",
    "    del waveform, mel_spect\n",
    "    gc.collect()\n",
    "\n",
    "test_data = pd.DataFrame(test_data, columns=['filename', 'emotion'])\n",
    "test_data.to_csv(\"test_data.csv\", index=False)\n",
    "print(\"Test Images Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ebec0de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:55:15.768718Z",
     "iopub.status.busy": "2021-08-29T09:55:15.768074Z",
     "iopub.status.idle": "2021-08-29T09:55:16.014472Z",
     "shell.execute_reply": "2021-08-29T09:55:16.014977Z"
    },
    "papermill": {
     "duration": 0.274575,
     "end_time": "2021-08-29T09:55:16.015161",
     "exception": false,
     "start_time": "2021-08-29T09:55:15.740586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217, 334, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "im = cv2.imread(\"/kaggle/working/TestImages/692.mp3.png\")\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66f89acc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:55:16.066567Z",
     "iopub.status.busy": "2021-08-29T09:55:16.065947Z",
     "iopub.status.idle": "2021-08-29T09:55:16.069454Z",
     "shell.execute_reply": "2021-08-29T09:55:16.068849Z"
    },
    "papermill": {
     "duration": 0.03166,
     "end_time": "2021-08-29T09:55:16.069615",
     "exception": false,
     "start_time": "2021-08-29T09:55:16.037955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLinks\n",
    "# FileLinks('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe158e9",
   "metadata": {
    "papermill": {
     "duration": 0.022349,
     "end_time": "2021-08-29T09:55:16.114546",
     "exception": false,
     "start_time": "2021-08-29T09:55:16.092197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16b29926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:55:16.164380Z",
     "iopub.status.busy": "2021-08-29T09:55:16.163447Z",
     "iopub.status.idle": "2021-08-29T09:55:16.167127Z",
     "shell.execute_reply": "2021-08-29T09:55:16.166436Z"
    },
    "papermill": {
     "duration": 0.030213,
     "end_time": "2021-08-29T09:55:16.167265",
     "exception": false,
     "start_time": "2021-08-29T09:55:16.137052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mel_spect = librosa.feature.melspectrogram(y=yt, sr=sr, n_fft=2048//2, hop_length=512//2)\n",
    "# mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "# librosa.display.specshow(mel_spect, y_axis='mel', fmax=9000, x_axis='time');\n",
    "#plt.title('Mel Spectrogram');\n",
    "# plt.savefig('x.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "100a941e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:55:16.216830Z",
     "iopub.status.busy": "2021-08-29T09:55:16.216155Z",
     "iopub.status.idle": "2021-08-29T09:55:16.219946Z",
     "shell.execute_reply": "2021-08-29T09:55:16.219313Z"
    },
    "papermill": {
     "duration": 0.030617,
     "end_time": "2021-08-29T09:55:16.220089",
     "exception": false,
     "start_time": "2021-08-29T09:55:16.189472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def read_audio(fp):\n",
    "#     with audioread.audio_open(fp) as f:\n",
    "#         # totalsec contains the length in float\n",
    "#         totalsec = f.duration\n",
    "#     return totalsec\n",
    "\n",
    "# train_durations = []\n",
    "# for fn, label in tqdm(train_df.values):\n",
    "#     path_load = os.path.join(TRAIN_fp,fn)\n",
    "#     train_durations.append(read_audio(path_load))\n",
    "    \n",
    "    \n",
    "# test_durations = []\n",
    "# for fn in tqdm(os.listdir(TEST_fp)):\n",
    "#     path_load = os.path.join(TEST_fp,fn)\n",
    "#     test_durations.append(read_audio(path_load))\n",
    "\n",
    "# sum(test_durations)/len(test_durations),min(test_durations), max(test_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc19c538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:55:16.270783Z",
     "iopub.status.busy": "2021-08-29T09:55:16.270122Z",
     "iopub.status.idle": "2021-08-29T09:55:16.273795Z",
     "shell.execute_reply": "2021-08-29T09:55:16.273279Z"
    },
    "papermill": {
     "duration": 0.031405,
     "end_time": "2021-08-29T09:55:16.273942",
     "exception": false,
     "start_time": "2021-08-29T09:55:16.242537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# save_path = \"/kaggle/working/TrainImgFiles\"\n",
    "# if not os.path.exists(save_path):\n",
    "#     os.mkdir(save_path)\n",
    "    \n",
    "# train_data = []\n",
    "# for fn, label in tqdm(train_df.values):\n",
    "#     path_load = os.path.join(TRAIN_fp,fn)\n",
    "#     y, sr = audioread_load(path_load, duration=5)\n",
    "#     yt, _ = librosa.effects.trim(y)\n",
    "#     mel_spect = librosa.feature.melspectrogram(y=yt, sr=sr, n_fft=1024, hop_length=256)\n",
    "#     mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "#     print(mel_spect.shape)\n",
    "#     librosa.display.specshow(mel_spect, y_axis='mel', fmax=9000, x_axis='time')\n",
    "# #     save_dir = os.path.join(save_path,label)\n",
    "# #     if not os.path.exists(save_dir):\n",
    "# #         os.mkdir(save_dir)\n",
    "#     img_fn = f\"{fn.split('.')[0]}.png\"\n",
    "#     plt.savefig(os.path.join(save_path, img_fn))\n",
    "#     train_data.append([img_fn, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af0574d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:55:16.326007Z",
     "iopub.status.busy": "2021-08-29T09:55:16.325311Z",
     "iopub.status.idle": "2021-08-29T09:55:16.328138Z",
     "shell.execute_reply": "2021-08-29T09:55:16.328734Z"
    },
    "papermill": {
     "duration": 0.031991,
     "end_time": "2021-08-29T09:55:16.328912",
     "exception": false,
     "start_time": "2021-08-29T09:55:16.296921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import librosa as lb\n",
    "# import soundfile as sf\n",
    "\n",
    "\n",
    "# def audio_features(file_title, mfcc, chroma, mel):\n",
    "#     with sf.SoundFile(file_title) as audio_recording:\n",
    "#         audio = audio_recording.read(dtype=\"float32\")\n",
    "#         sample_rate = audio_recording.samplerate\n",
    "        \n",
    "#         if chroma:\n",
    "#             stft=np.abs(lb.stft(audio))\n",
    "#             result=np.array([])\n",
    "#         if mfcc:\n",
    "#             mfccs=np.mean(lb.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "#             result=np.hstack((result, mfccs))\n",
    "#         if chroma:\n",
    "#             chroma=np.mean(lb.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "#             result=np.hstack((result, chroma))\n",
    "#         if mel:\n",
    "#             mel=np.mean(lb.feature.melspectrogram(audio, sr=sample_rate).T,axis=0)\n",
    "#             result=np.hstack((result, mel))\n",
    "#         return result\n",
    "\n",
    "\n",
    "\n",
    "# def loading_audio_data():\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for file in glob.glob(\"data//Actor_*//*.wav\"):\n",
    "#         file_path=os.path.basename(file)\n",
    "#         emotion = emotion_labels[file_path.split(\"-\")[2]]\n",
    "#         if emotion not in focused_emotion_labels:\n",
    "#             continue\n",
    "#         feature = audio_features(file, mfcc=True, chroma=True, mel=True)\n",
    "        \n",
    "#         x.append(feature)\n",
    "#         y.append(emotion)\n",
    "#     final_dataset = train_test_split(np.array(x), y, test_size=0.1, random_state=9)\n",
    "#     return final_dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6182.026812,
   "end_time": "2021-08-29T09:55:19.008118",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-29T08:12:16.981306",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1c3ad08efb624162a25662e068036c13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5551ae7a794a438d882cfa912c722640",
       "placeholder": "​",
       "style": "IPY_MODEL_7dc43e62f57341c1b01bc10497258b59",
       "value": " 5816/5816 [1:11:44&lt;00:00,  1.51it/s]"
      }
     },
     "1c9a1cee7edc46e2a78f96b330db58c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7fdd0be657634c24bb89319b185e69b1",
       "placeholder": "​",
       "style": "IPY_MODEL_4eb28199cbce4b95870bb344c185b7f8",
       "value": "100%"
      }
     },
     "1fd054dc0edf474fbebb954c2cffdf3b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "31b3fffc7ef042978c5606b4646ea679": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "38baab112e74470faf5fa7340203fc6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_56c2bf0bdbbb4dceb004036b9fe61314",
       "placeholder": "​",
       "style": "IPY_MODEL_bf036953b3c64ffb8a648a176ba380c4",
       "value": "100%"
      }
     },
     "4d0f418c68924bef8e1bb296dda49912": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_762b8b092c9547d7a44d6c04edbea369",
       "max": 5816.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_31b3fffc7ef042978c5606b4646ea679",
       "value": 5816.0
      }
     },
     "4eb28199cbce4b95870bb344c185b7f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5551ae7a794a438d882cfa912c722640": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56c2bf0bdbbb4dceb004036b9fe61314": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5751e73030c24cb1ad8f14d685ad46e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "762b8b092c9547d7a44d6c04edbea369": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7aaf55c0a4ff40d5b5ba25c97222d877": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1c9a1cee7edc46e2a78f96b330db58c4",
        "IPY_MODEL_4d0f418c68924bef8e1bb296dda49912",
        "IPY_MODEL_1c3ad08efb624162a25662e068036c13"
       ],
       "layout": "IPY_MODEL_1fd054dc0edf474fbebb954c2cffdf3b"
      }
     },
     "7dc43e62f57341c1b01bc10497258b59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7fdd0be657634c24bb89319b185e69b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ec993c9f77241a5a85c94e7c10552c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a341016f36594cd09d6db8b187e57783": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b782545f782345769b4be415e11bee68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bbdcff8e76844e3dbd845743892010fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f8828968ef92436dac5edbc8347832c9",
       "max": 2492.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5751e73030c24cb1ad8f14d685ad46e9",
       "value": 2492.0
      }
     },
     "bf036953b3c64ffb8a648a176ba380c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e76272f6e440457d9ea80176727d4654": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_38baab112e74470faf5fa7340203fc6f",
        "IPY_MODEL_bbdcff8e76844e3dbd845743892010fc",
        "IPY_MODEL_fb3fddd5d2ac44d091d6ff11eed932a5"
       ],
       "layout": "IPY_MODEL_b782545f782345769b4be415e11bee68"
      }
     },
     "f8828968ef92436dac5edbc8347832c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb3fddd5d2ac44d091d6ff11eed932a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8ec993c9f77241a5a85c94e7c10552c0",
       "placeholder": "​",
       "style": "IPY_MODEL_a341016f36594cd09d6db8b187e57783",
       "value": " 2492/2492 [30:30&lt;00:00,  1.33it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
